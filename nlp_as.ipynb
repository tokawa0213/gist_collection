{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#nlp_as.txt\n",
        "#http://www.george-orwell.org/1984/0.html\n",
        "#DATA VISUALIZATION\n",
        "with open(\"nlp_as.txt\") as f:\n",
        "    for line in f.readlines()[:30]:    \n",
        "        print(line)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PART ONE\n",
            "\n\n\n\n\n\n\n",
            "Chapter 1\n",
            "\n\n\n\n\n\n\n",
            "It was a bright cold day in April, and the clocks were striking thirteen.\n",
            "\n",
            "Winston Smith, his chin nuzzled into his breast in an effort to escape the\n",
            "\n",
            "vile wind, slipped quickly through the glass doors of Victory Mansions,\n",
            "\n",
            "though not quickly enough to prevent a swirl of gritty dust from entering\n",
            "\n",
            "along with him.\n",
            "\n\n\n",
            "The hallway smelt of boiled cabbage and old rag mats. At one end of it a\n",
            "\n",
            "coloured poster, too large for indoor display, had been tacked to the wall.\n",
            "\n",
            "It depicted simply an enormous face, more than a metre wide: the face of a\n",
            "\n",
            "man of about forty-five, with a heavy black moustache and ruggedly handsome\n",
            "\n",
            "features. Winston made for the stairs. It was no use trying the lift. Even\n",
            "\n",
            "at the best of times it was seldom working, and at present the electric\n",
            "\n",
            "current was cut off during daylight hours. It was part of the economy drive\n",
            "\n",
            "in preparation for Hate Week. The flat was seven flights up, and Winston,\n",
            "\n",
            "who was thirty-nine and had a varicose ulcer above his right ankle, went\n",
            "\n",
            "slowly, resting several times on the way. On each landing, opposite the\n",
            "\n",
            "lift-shaft, the poster with the enormous face gazed from the wall. It was\n",
            "\n",
            "one of those pictures which are so contrived that the eyes follow you about\n",
            "\n",
            "when you move. BIG BROTHER IS WATCHING YOU, the caption beneath it ran.\n",
            "\n\n\n",
            "Inside the flat a fruity voice was reading out a list of figures which had\n",
            "\n",
            "something to do with the production of pig-iron. The voice came from an\n",
            "\n"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(a)Numbre of word token and word type\n",
        "\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "with open(\"nlp_as.txt\") as f:\n",
        "    PATTERN = r'([^a-zA-Z0-9])'\n",
        "    WORD_SET = []\n",
        "    for line in f:\n",
        "        line = line.lower()\n",
        "        line = re.sub(PATTERN,r\" \\1 \",line)\n",
        "        WORD_SET.extend(line.split())\n",
        "WORD_COUNTER = Counter(WORD_SET)\n",
        "WORD_TOKEN = len(WORD_SET)\n",
        "WORD_TYPE = len(set(WORD_SET))\n",
        "print(\"WORD_TOKEN: \" + str(WORD_TOKEN))\n",
        "print(\"WORD_TYPE: \" + str(WORD_TYPE))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WORD_TOKEN: 124236\n",
            "WORD_TYPE: 8878\n"
          ]
        }
      ],
      "execution_count": 81,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(b) find all bigrams\n",
        "import nltk\n",
        "corpus = nltk.Text(WORD_SET)\n",
        "bigram = nltk.bigrams(corpus)\n",
        "cfd = nltk.ConditionalFreqDist(bigram)\n",
        "ALL_BIGRAMS = []\n",
        "BIGRAM_FREQUENCY = defaultdict(int)\n",
        "for first_word,second_word_dict in cfd.items():\n",
        "    for second_word,value in second_word_dict.items():\n",
        "        BIGRAM_FREQUENCY[first_word + \" \" + second_word] += value\n",
        "ALL_BIGRAMS = list(BIGRAM_FREQUENCY.keys())\n",
        "print(ALL_BIGRAMS[:30])\n",
        "BIGRAM_LENGTH = len(ALL_BIGRAMS)\n",
        "print(\"NUMBER OF BIGRAMS : \" + str(BIGRAM_LENGTH))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['part one', 'part of', 'part ,', 'part in', 'part two', 'part .', 'part -', 'part three', 'one chapter', 'one end', 'one of', 'one on', 'one corner', 'one ,', 'one .', 'one had', 'one side', 'one very', \"one '\", 'one with', 'one should', 'one knew', 'one was', 'one even', 'one felt', 'one object', 'one moment', 'one wrenches', 'one seemed', 'one into']\n",
            "NUMBER OF BIGRAMS : 52048\n"
          ]
        }
      ],
      "execution_count": 98,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(c) Percentage of actual bigram over possible bigram\n",
        "BIGRAM_LENGTH*100/(WORD_TYPE*WORD_TYPE)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 58,
          "data": {
            "text/plain": [
              "0.06355821138731339"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 58,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(d) Calculate the possibility of the sentence\n",
        "\n",
        "sample_sentence = \"it was one of those pictures which are so contrived that the eyes follow you about when you move .\"\n",
        "sample_sentence = sample_sentence.split()\n",
        "#Calculating by unigrams\n",
        "\n",
        "total = 1\n",
        "print(\"WORD COUNT ALL_WORDS PERCENTAGE\")\n",
        "for i in sample_sentence:\n",
        "    print(i,WORD_COUNTER[i],WORD_TOKEN,WORD_COUNTER[i]/float(WORD_TOKEN))\n",
        "    total *= WORD_COUNTER[i]/float(WORD_TOKEN)\n",
        "print()\n",
        "print(\"Calulated sentence probability using unigram:\",total*100)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WORD COUNT ALL_WORDS PERCENTAGE\n",
            "it 1920 124236 0.015454457645127016\n",
            "was 2316 124236 0.018641939534434465\n",
            "one 443 124236 0.0035657941337454524\n",
            "of 3493 124236 0.02811584403876493\n",
            "those 51 124236 0.00041050903119868636\n",
            "pictures 2 124236 1.6098393380340642e-05\n",
            "which 472 124236 0.0037992208377603917\n",
            "are 296 124236 0.002382562220290415\n",
            "so 208 124236 0.0016742329115554267\n",
            "contrived 4 124236 3.2196786760681284e-05\n",
            "that 1507 124236 0.012130139412086674\n",
            "the 6522 124236 0.05249686081329084\n",
            "eyes 120 124236 0.0009659036028204385\n",
            "follow 9 124236 7.24427702115329e-05\n",
            "you 1011 124236 0.008137737853762194\n",
            "about 152 124236 0.0012234778969058887\n",
            "when 318 124236 0.002559644547474162\n",
            "you 1011 124236 0.008137737853762194\n",
            "move 16 124236 0.00012878714704272514\n",
            ". 6102 124236 0.0491161982034193\n",
            "\n",
            "Calulated sentence probability using unigram: 5.444187944640978e-52\n"
          ]
        }
      ],
      "execution_count": 89,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "sample_sentence =  \"it was one of those pictures which are so contrived that the eyes follow you about when you move .\"\n",
        "sample_sentence = \". \" + sample_sentence\n",
        "sample_sentence = nltk.bigrams(sample_sentence.split())\n",
        "\n",
        "#Calculating by bigrams\n",
        "\n",
        "print(\"BIGRAM COUNT ALL_BIGRAMS PERCENTAGE\")\n",
        "total = 1\n",
        "for word in sample_sentence:\n",
        "    key = \" \".join(word)\n",
        "    print(key,BIGRAM_FREQUENCY[key],BIGRAM_LENGTH,float(BIGRAM_FREQUENCY[key])/BIGRAM_LENGTH)\n",
        "    total *= float(BIGRAM_FREQUENCY[key])/BIGRAM_LENGTH\n",
        "\n",
        "print()\n",
        "print(\"Calulated sentence probability using bigram:\",total*100)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BIGRAM COUNT ALL_BIGRAMS PERCENTAGE\n",
            ". it 460 52048 0.008837995696280356\n",
            "it was 608 52048 0.01168152474638795\n",
            "was one 15 52048 0.00028819551183522903\n",
            "one of 61 52048 0.0011719950814632646\n",
            "of those 14 52048 0.0002689824777128804\n",
            "those pictures 1 52048 1.92130341223486e-05\n",
            "pictures which 1 52048 1.92130341223486e-05\n",
            "which are 4 52048 7.68521364893944e-05\n",
            "are so 1 52048 1.92130341223486e-05\n",
            "so contrived 1 52048 1.92130341223486e-05\n",
            "contrived that 1 52048 1.92130341223486e-05\n",
            "that the 147 52048 0.0028243160159852443\n",
            "the eyes 27 52048 0.0005187519213034123\n",
            "eyes follow 1 52048 1.92130341223486e-05\n",
            "follow you 1 52048 1.92130341223486e-05\n",
            "you about 1 52048 1.92130341223486e-05\n",
            "about when 1 52048 1.92130341223486e-05\n",
            "when you 30 52048 0.0005763910236704581\n",
            "you move 1 52048 1.92130341223486e-05\n",
            "move . 5 52048 9.6065170611743e-05\n",
            "\n",
            "Calulated sentence probability using bigram: 4.008316174827568e-77\n"
          ]
        }
      ],
      "execution_count": 109,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test for an unknown sentece\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}